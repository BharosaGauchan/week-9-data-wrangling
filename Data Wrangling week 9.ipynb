{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2491b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : [[0.5488135  0.71518937 0.60276338 0.54488318]\n",
      " [0.4236548  0.64589411 0.43758721 0.891773  ]\n",
      " [0.96366276 0.38344152 0.79172504 0.52889492]]\n",
      "dataframe:           0         1         2         3\n",
      "0  0.548814  0.715189  0.602763  0.544883\n",
      "1  0.423655  0.645894  0.437587  0.891773\n",
      "2  0.963663  0.383442  0.791725  0.528895\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from numpy import savetxt\n",
    "from numpy import loadtxt\n",
    "# create 3 by 4 random array\n",
    "np.random.seed(0)\n",
    "np = np.random.rand(12).reshape((3,4))\n",
    "np\n",
    "    \n",
    "#Save the array as a CSV named np.csv\n",
    "savetxt(r\"C:\\Users\\bharo\\OneDrive\\Documents\\np.csv\", np,delimiter=',')\n",
    "\n",
    "# load array\n",
    "data = loadtxt(r'C:\\Users\\bharo\\OneDrive\\Documents\\np.csv', delimiter=',')\n",
    "# print the array\n",
    "print('data :', data)\n",
    "\n",
    "#Create a DataFrame from the file and print the results\n",
    "df = pd.read_csv(r'C:\\Users\\bharo\\OneDrive\\Documents\\np.csv',header=None)\n",
    "print ('dataframe:',df)\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(r'C:\\Users\\bharo\\OneDrive\\Documents\\np_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01b4eec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size  =  1460\n",
      "pickled size = 1460\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Generate a 365X4 NumPy array with random values\n",
    "rand = np.random.random((365,4))\n",
    "\n",
    "#Store the array in a CSV file and check its size\n",
    "savetxt(r\"C:\\Users\\bharo\\OneDrive\\Documents\\rand.csv\",rand,delimiter=',')\n",
    "\n",
    "rand_data = loadtxt(r\"C:\\Users\\bharo\\OneDrive\\Documents\\rand.csv\",delimiter=',')\n",
    "print ('size  = ', rand_data.size)\n",
    "\n",
    "# Create a DataFrame rand array   \n",
    "df2 = pd.read_csv(r\"C:\\Users\\bharo\\OneDrive\\Documents\\rand.csv\", header = None)\n",
    "\n",
    "#write pickle\n",
    "df2.to_pickle(r\"C:\\Users\\bharo\\OneDrive\\Documents\\pickled.pkl\") \n",
    "\n",
    "#retrieve the pickle\n",
    "df_pickle = pd.read_pickle(r'C:\\Users\\bharo\\OneDrive\\Documents\\pickled.pkl')\n",
    "print('pickled size =', df_pickle.size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcca6099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0         0         1         2         3\n",
      "0             0  0.771623  0.630721  0.030284  0.978968\n",
      "1             1  0.387491  0.846450  0.373209  0.898912\n",
      "2             2  0.440448  0.764907  0.910777  0.864336\n",
      "3             3  0.432409  0.014447  0.125783  0.421575\n",
      "4             4  0.399064  0.821272  0.694867  0.333194\n",
      "..          ...       ...       ...       ...       ...\n",
      "360         360  0.798269  0.771342  0.431811  0.981579\n",
      "361         361  0.885795  0.196717  0.300004  0.851064\n",
      "362         362  0.125753  0.338149  0.628050  0.872884\n",
      "363         363  0.412660  0.784091  0.397745  0.470799\n",
      "364         364  0.407235  0.789529  0.936405  0.743909\n",
      "\n",
      "[365 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Using the array created in #2, create an excel file with this data\n",
    "df2.to_excel(r\"C:\\Users\\bharo\\OneDrive\\Documents\\excel.xlsx\")\n",
    "\n",
    "# create a dataframe from the excel\n",
    "df_excel = pd.read_excel(r\"C:\\Users\\bharo\\OneDrive\\Documents\\excel.xlsx\")\n",
    "print(df_excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "135b106e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netherlands\n",
      "updated country : Switzerland\n"
     ]
    }
   ],
   "source": [
    "# Using this JSON string, parse a JSON string with the loads() function\n",
    "import json\n",
    "x ='{\"country\":\"Netherlands\",\"dma_code\":\"0\",\"timezone\":\"Europe\\/Amsterdam\",\"area_code\":\"0\",\"ip\":\"46.19.37.108\",\"asn\":\"AS196752\",\"continent_code\":\"EU\",\"isp\":\"Tilaa V.O.F.\",\"longitude\":5.75,\"latitude\":52.5,\"country_code\":\"NL\",\"country_code3\":\"NLD\"}'\n",
    "#parse string\n",
    "y = json.loads(x)\n",
    "print(y[\"country\"])\n",
    "#Overwrite the value for Netherlands with a value of your choice\n",
    "y['country'] = 'Switzerland'\n",
    "print( 'updated country :', y[\"country\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1d252252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               0\n",
      "country              Switzerland\n",
      "dma_code                       0\n",
      "timezone        Europe/Amsterdam\n",
      "area_code                      0\n",
      "ip                  46.19.37.108\n",
      "asn                     AS196752\n",
      "continent_code                EU\n",
      "isp                 Tilaa V.O.F.\n",
      "longitude                   5.75\n",
      "latitude                    52.5\n",
      "country_code                  NL\n",
      "country_code3                NLD\n",
      "\n",
      "\n",
      " updated country:\n",
      "                                0\n",
      "country                  Denmark\n",
      "dma_code                       0\n",
      "timezone        Europe/Amsterdam\n",
      "area_code                      0\n",
      "ip                  46.19.37.108\n",
      "asn                     AS196752\n",
      "continent_code                EU\n",
      "isp                 Tilaa V.O.F.\n",
      "longitude                   5.75\n",
      "latitude                    52.5\n",
      "country_code                  NL\n",
      "country_code3                NLD\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n    \"0\": {\\n        \"country\": \"Denmark\",\\n        \"dma_code\": \"0\",\\n        \"timezone\": \"Europe/Amsterdam\",\\n        \"area_code\": \"0\",\\n        \"ip\": \"46.19.37.108\",\\n        \"asn\": \"AS196752\",\\n        \"continent_code\": \"EU\",\\n        \"isp\": \"Tilaa V.O.F.\",\\n        \"longitude\": 5.75,\\n        \"latitude\": 52.5,\\n        \"country_code\": \"NL\",\\n        \"country_code3\": \"NLD\"\\n    }\\n}'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the Pandas read_json() function, we can either create a pandas Series or DataFrame – taking the \n",
    "#JSON string from #4, create a series\n",
    "df2 = pd.DataFrame.from_dict(y, orient=\"index\")\n",
    "print(df2)\n",
    "\n",
    "#Change the country value again to your choice and convert the Pandas Series to a JSON string\n",
    "df2 = df2.replace(['Switzerland'], 'Denmark')\n",
    "print ('\\n\\n updated country:\\n',df2)\n",
    "\n",
    "result = df2.to_json()\n",
    "parsed = json.loads(result)\n",
    "json.dumps(parsed, indent=4)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9f9440f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First div: \n",
      " <div class=\"tile\">\n",
      "<h4>Development</h4>\n",
      "     0.10.1 - July 2014<br/>\n",
      "</div>\n",
      "first div text: ['tile']\n",
      "first dfn text: Quare attende, quaeso.\n",
      "Link text: loripsum.net URL: http://loripsum.net/\n",
      "Link text: Poterat autem inpune; URL: http://loripsum.net/\n",
      "Link text: Is es profecto tu. URL: http://loripsum.net/\n",
      "0 ['\\n', <h4>Development</h4>, '\\n     0.10.1 - July 2014', <br/>, '\\n']\n",
      "1 ['\\n', <h4>Official Release</h4>, '\\n     0.10.0 June 2014', <br/>, '\\n']\n",
      "2 ['\\n', <h4>Previous Release</h4>, '\\n     0.09.1 June 2013', <br/>, '\\n']\n",
      "# Tile classes 2\n",
      "using CSS selector \n",
      " [<div class=\"notile\">\n",
      "<h4>Previous Release</h4>\n",
      "     0.09.1 June 2013<br/>\n",
      "</div>]\n",
      "Selecting ordered list list items\n",
      " [<li>Cur id non ita fit?</li>, <li>In qua si nihil est praeter rationem, sit in una virtute finis bonorum;</li>]\n",
      "Second list item in ordered list [<li>In qua si nihil est praeter rationem, sit in una virtute finis bonorum;</li>]\n",
      "Searching for text string ['\\n     0.10.1 - July 2014', '\\n     0.10.0 June 2014']\n"
     ]
    }
   ],
   "source": [
    "# Starting on page 124 – follow along with the BeautifulSoup exercise to scrape data from the HTML \n",
    "# page included in the GitHub repo. This exercise is great practice for your Term Project Milestone 4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "#open HTML file and create BeautifulSoup Object\n",
    "soup = BeautifulSoup(open('C:/Users/bharo/Downloads/loremIpsum.html'),\"lxml\")\n",
    "#access first div element\n",
    "print ('First div: \\n', soup.div)\n",
    "\n",
    "# print class attribute value of the <div> tag\n",
    "print( 'first div text:',soup.div['class'])\n",
    "\n",
    "#print text of the first <dfn> tag\n",
    "print ('first dfn text:', soup.dl.dt.dfn.text)\n",
    "\n",
    "#locate all the hyperlinks with the find_all() method\n",
    "for link in soup.find_all('a'):\n",
    "    print('Link text:', link.string,'URL:',link.get('href'))\n",
    "#access the content of all <div> tags\n",
    "for i, div in enumerate(soup('div')):\n",
    "   print(i, div.contents)\n",
    "\n",
    "# find the number of <div> tags with the class \"tile\"\n",
    "tile_class = soup.find_all(\"div\", class_=\"tile\")\n",
    "print(\"# Tile classes\", len(tile_class))\n",
    "\n",
    "#select elements with CSS patterns with CSS selector\n",
    "print('using CSS selector \\n', soup.select('div.notile'))\n",
    "\n",
    "#select the first two list items in the ordered list\n",
    "print(\"Selecting ordered list list items\\n\", soup.select(\"ol > li\")[:2])\n",
    "\n",
    "# select the second list items\n",
    "print(\"Second list item in ordered list\", soup.select(\"ol > li:nth-of-type(2)\"))\n",
    "\n",
    "#select all the text nodes containing the string 2014 with text attribute:\n",
    "print(\"Searching for text string\", soup.find_all(string=re.compile(\"2014\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daef0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
